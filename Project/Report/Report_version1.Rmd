---
title: "Kaggle Competiotion Report"
author: " The Free Riders: Denitsa Panova, Felix Gutmann, Thomas Vicente"
date: "March 16, 2016"
output: html_document
---

# Introducion

This is a report describing the results and approaches undertaken by the Free Riders team for the Kaaggle competion for Advanced Computational Methods and Machine Learning classes in Barcelona Graduate School of Economics, Spain.  
The project goal is to predict the popularity of an online news articles. All articles are taken from the website mashable.com. Popularity classes are in the range from 1 to 5, where 1 is the least popular and 5 the most. The separtion is based on the number of times a particular article has been shared, the popularity indicator we use. The whole data set is divided into two parts - training (30 000 obsrevations) and testing (9 644 obsrevations). From now on we refer to them (in the report and the R scripts) as the training and the test. In order to predict popularity classes we utilize machine learning techniques. We implement  **number** algorithms, ranging from a single model type ( like Random forest) to multiple models, for example the ensemble technique. A more detailed discussion regarding all aproaches can be found in the second part of the report - Predictions.  
The data set, acquired and preprocessed by K. Fernandes et al. has 59 extracted features (excluding popularity).  
In order to acquire more extensive knowledge of the provided data set, we conduct data exploration. This exploration consists of summarary of the variables (Riding-free-on-KAGGLE/Project/Work/R_Scripts/F00_DataInspection.R) and also identifying "ambigious" data points. For example, such a point is id=16546 whose "kw_max_avg" is the maximum, it is extremely far away from the other data points in the "kw_max_avg" and is of popularity class1. We partition the data in classes, determine similar points ( which do not act "in the normal manner"), store their id's (Riding-free-on-KAGGLE/Project/Data/Raw_Data/outliers_id) and create another data set which excludes those observations. We utalize both data sets when establishing the accuracy of our mechine learning techniques. Although we acknowledge that there are "not-normal" points in the original data set, we still use it for the prediction accuracy is better using the full data set.  
